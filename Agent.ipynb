{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.11", "language": "python"}, "language_info": {"name": "python", "version": "3.11.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "code", "source": "# installations\n%pip install langchain | tail -n 1\n%pip install langchain-ibm | tail -n 1\n%pip install langchain-community | tail -n 1\n%pip install ibm-watsonx-ai | tail -n 1\n%pip install chromadb | tail -n 1\n%pip install tiktoken | tail -n 1\n%pip install bs4 | tail -n 1", "metadata": {"id": "560031ca-5eb8-4f8f-ad44-855f12a3e445"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "# imports\nimport getpass\n\nfrom langchain_ibm import WatsonxEmbeddings, WatsonxLLM\nfrom langchain.vectorstores import Chroma\nfrom langchain_community.document_loaders import WebBaseLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain.prompts import PromptTemplate\nfrom langchain.tools import tool\nfrom langchain.tools.render import render_text_description_and_args\nfrom langchain.agents.output_parsers import JSONAgentOutputParser\nfrom langchain.agents.format_scratchpad import format_log_to_str\nfrom langchain.agents import AgentExecutor\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain_core.runnables import RunnablePassthrough\nfrom ibm_watsonx_ai.foundation_models.utils.enums import EmbeddingTypes\nfrom ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams", "metadata": {"id": "032899f4-f7c7-4a7d-8ef4-f30bebec49cc"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "#Setting Up API key and Project ID\ncredentials = {\n    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n    \"apikey\": getpass.getpass(\"Please enter your watsonx.ai Runtime API key (hit enter): \")\n}\n\nproject_id = getpass.getpass(\"Please enter your project ID (hit enter): \")", "metadata": {"id": "3495b1ba-708c-455f-a459-e7a68fe5d654"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "#Initialization of basic tools with no agents\nllm = WatsonxLLM(\n    model_id= \"ibm/granite-3-8b-instruct\", \n    url=credentials.get(\"url\"),\n    apikey=credentials.get(\"apikey\"),\n    project_id=project_id,\n    params={\n        GenParams.DECODING_METHOD: \"greedy\",\n        GenParams.TEMPERATURE: 0,\n        GenParams.MIN_NEW_TOKENS: 5,\n        GenParams.MAX_NEW_TOKENS: 250,\n        GenParams.STOP_SEQUENCES: [\"Human:\", \"Observation\"],\n    },\n)", "metadata": {"id": "a806a345-7e6b-4453-b8b3-d383f4eb7f54"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "#prompt template in case you want to ask multiple questions.\ntemplate = \"Answer the {query} accurately. If you do not know the answer, simply say you do not know.\"\nprompt = PromptTemplate.from_template(template)\n#set up a chain with our prompt and our LLM. This allows the generative model to produce a response.\nagent = prompt | llm", "metadata": {"id": "175e7a0e-2df1-441e-943e-b67685e94b0a"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "#Ask the Agent a question\nagent.invoke({\"query\": \"What is the optimal High Jump technique\"})", "metadata": {"id": "6f6935e3-02e2-4af6-b94c-b15db9ae3221"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "#Asking another set of Questions\nagent.invoke({\"query\": \"What was the takeoff angle of my knee?\"})", "metadata": {"id": "3cafe8bb-24dc-43a1-944c-27aae9f80a5a"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "#Asking another set of Questions\nagent.invoke({\"query\": \"What was the takeoff angle of my knee during my jump?\"})", "metadata": {"id": "79b1660e-5a09-4872-89f6-a1be28fe5424"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "#Asking another set of Questions\nagent.invoke({\"query\": \"If you had access to my jump data via MediaPipe, would you be able to analyze the physical movements?\"})", "metadata": {"id": "3d80f4e8-8d62-4356-8af9-8752f076ef74"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "#Websites that data is extracted from... Data Source/knowledge base\nurls = [\n    \"https://en.wikipedia.org/wiki/High_jump\",\n    \"https://worldathletics.org/disciplines/jumps/high-jump\",\n    \"https://athleticssa.org.za/SportsInfo/Coaching-High-Jump.pdf\",\n    \"https://coachathletics.com.au/coaching-education/how-to-coach-the-fosbury-flop-drill-progression-for-teaching-high-jump\"\n\n]", "metadata": {"id": "420c003d-2609-4061-9821-ad165aa0a6f0"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "#Loading documents using LangChain WebBaseLoader from urls listed\ndocs = [WebBaseLoader(url).load() for url in urls]\ndocs_list = [item for sublist in docs for item in sublist]\ndocs_list[0]", "metadata": {"id": "73a5ab28-a377-4a66-a0e4-d05ec59669cb", "scrolled": true}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "#Text Splitter\ntext_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n    chunk_size=250, chunk_overlap=0\n)\ndoc_splits = text_splitter.split_documents(docs_list)", "metadata": {"id": "6bfc7b7e-fd0e-4674-a1b5-9b5242b30884"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "#Embedding models\nembeddings = WatsonxEmbeddings(\n    model_id=EmbeddingTypes.IBM_SLATE_30M_ENG.value,\n    url=credentials[\"url\"],\n    apikey=credentials[\"apikey\"],\n    project_id=project_id,\n)", "metadata": {"id": "ded5cac5-ff12-4b2e-bd02-24110ab90c41"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "#Storage of embedded documents using Chroma DB\nvectorstore = Chroma.from_documents(\n    documents=doc_splits,\n    collection_name=\"agentic-rag-chroma\",\n    embedding=embeddings,\n)", "metadata": {"id": "c774b8f4-e88b-4664-b1b9-2a025fb2276c"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "#Access Information in vector store\nretriever = vectorstore.as_retriever()", "metadata": {"id": "fa32cc04-9b22-4089-a463-89616205dbf3"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "@tool\ndef get_HighJump_Info(question: str, metrics: Optional[dict] = None) -> str:\n    \"\"\"\n    Get context about High Jump including technique, approach, optimal velocity, hip height, and body angles.\n    Optionally include MediaPipe pose estimation metrics to evaluate form based on key points.\n\n    Expected metrics keys (optional): hip_angle, knee_angle, takeoff_velocity, max_hip_height, keypoints\n    \"\"\"\n    context = retriever.invoke(question)\n    feedback = []\n\n    # Only analyze KPIs if metrics are provided\n    if metrics:\n        hip_angle = metrics.get(\"hip_angle\", None)\n        knee_angle = metrics.get(\"knee_angle\", None)\n        velocity = metrics.get(\"takeoff_velocity\", None)\n        hip_height = metrics.get(\"max_hip_height\", None)\n\n        # --- KPI Evaluations ---\n        if hip_angle is not None:\n            if hip_angle < 130:\n                feedback.append(f\"Hip angle of {hip_angle}\u00b0 is too low; work on knee drive.\")\n            else:\n                feedback.append(f\"Hip angle of {hip_angle}\u00b0 is strong.\")\n\n        if knee_angle is not None:\n            if knee_angle < 160:\n                feedback.append(f\"Knee angle of {knee_angle}\u00b0 suggests limited extension.\")\n            else:\n                feedback.append(f\"Knee angle of {knee_angle}\u00b0 shows good extension.\")\n\n        if velocity is not None:\n            if velocity < 3.5:\n                feedback.append(f\"Takeoff velocity of {velocity} m/s is below optimal. Increase run-up speed.\")\n            else:\n                feedback.append(f\"Takeoff velocity of {velocity} m/s is sufficient.\")\n\n        if hip_height is not None:\n            if hip_height < 0.85:\n                feedback.append(f\"Max hip height of {hip_height}m is low. Emphasize vertical lift at takeoff.\")\n            else:\n                feedback.append(f\"Hip height of {hip_height}m is excellent.\")\n\n        # Optionally include raw pose keypoints\n        keypoints = metrics.get(\"keypoints\", None)\n        if keypoints:\n            feedback.append(f\"Pose Keypoints received for analysis: {list(keypoints.keys())[:5]}... (truncated)\")\n\n    # Final response\n    return \"\\n\".join([\n        \" Technique Context:\\n\" + context,\n        \"\\n KPI Feedback:\\n\" + (\"\\n\".join(feedback) if feedback else \"No metrics provided.\")\n    ])\ntools = [get_HighJump_Info]\n", "metadata": {"id": "46c8db00-99db-48ce-a2f6-531fd434d05a"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "system_prompt = \"\"\"You are a Virtual High Jump Coach. Your role is to assist athletes by providing precise and constructive feedback about their high jump performance. You have access to the following tools: {tools}\n\nUse a JSON blob to select a tool by providing an \"action\" key (the tool name) and an \"action_input\" key (the input for that tool).  \nValid \"action\" values include: \"Final Answer\" or {tool_names}\n\nEach tool action must be wrapped in a JSON object like this:\n\n{{\n  \"action\": $TOOL_NAME,\n  \"action_input\": $INPUT\n}}\n\nAlways follow this reasoning pattern:\nQuestion: Athlete's question or comment  \nThought: Reflect on the athlete\u2019s movement data, technique reference, or biomechanical insight  \nAction:\n\n$JSON_BLOB\n\nObservation: Response or result from the tool  \n... (repeat Thought/Action/Observation N times if needed)  \nThought: I now understand how to best guide the athlete  \nAction:\n\n{{\n  \"action\": \"Final Answer\",\n  \"action_input\": \"Final coaching advice or explanation\"\n}}\n\"\"\"", "metadata": {"id": "c7b518c9-0282-44b4-9a08-ef1e600623d3"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "human_prompt = \"\"\"{input}\n\n{agent_scratchpad}\n\n(reminder to always respond in a JSON blob)\n\"\"\"", "metadata": {"id": "fff81f08-e5d3-4999-86d8-1b229c2645e1"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "prompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", system_prompt),\n        MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n        (\"human\", human_prompt),\n    ]\n)", "metadata": {"id": "be71e382-358f-43f9-91e2-2b2ce7b9d701"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "#finalize our prompt template by adding the tool names, descriptions and arguments using a partial prompt template.\n#This allows the agent to access the information pertaining to each tool\n#including the intended use cases and also means we can add and remove tools without altering our entire prompt template.\nprompt = prompt.partial(\n    tools=render_text_description_and_args(list(tools)),\n    tool_names=\", \".join([t.name for t in tools]),\n)", "metadata": {"id": "d9f4c55f-3058-4731-a22b-a8fd8bf8ed2c"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "#Setting up agents memory\n#use LangChain's ConversationBufferMemory() as a means of memory storage.\nmemory = ConversationBufferMemory()", "metadata": {"id": "0f733df2-3ce7-421a-9c68-55d385f6bb8c"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "#set up a chain with our agent's scratchpad, memory, prompt and the LLM.\n#The AgentExecutor class is used to execute the agent. It takes the agent, its tools, error handling approach, verbose parameter and memory as parameters.\nchain = (\n    RunnablePassthrough.assign(\n        agent_scratchpad=lambda x: format_log_to_str(x[\"intermediate_steps\"]),\n        chat_history=lambda x: memory.chat_memory.messages,\n    )\n    | prompt\n    | llm\n    | JSONAgentOutputParser()\n)\n\nagent_executor = AgentExecutor(\n    agent=chain, tools=tools, handle_parsing_errors=True, verbose=True, memory=memory\n)", "metadata": {"id": "211c118c-50d9-468d-8026-246b94d3b4a6"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "#We are now able to ask the agent questions.\nagent_executor.invoke({\"input\":\"Question})\"", "metadata": {"id": "cb79f632-4f00-4278-a79c-2f1b039bbf1f"}, "outputs": [], "execution_count": null}]}